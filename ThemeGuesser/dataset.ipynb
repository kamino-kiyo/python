{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c2aae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 3145728)           0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 200)               629145800 \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 804       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 629,186,804\n",
      "Trainable params: 629,186,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "3/3 [==============================] - 66s 6s/step - loss: 256.3646 - accuracy: 0.2536 - val_loss: 1.7997e-12 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 383.6704 - accuracy: 0.2679 - val_loss: 216.0807 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 307.4118 - accuracy: 0.2919 - val_loss: 49.9845 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 274.7555 - accuracy: 0.3062 - val_loss: 150.9192 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 265.7425 - accuracy: 0.3062 - val_loss: 102.9200 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 208.6995 - accuracy: 0.3254 - val_loss: 2.5487 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 124.0061 - accuracy: 0.3445 - val_loss: 24.8898 - val_accuracy: 0.5833\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 92.4225 - accuracy: 0.4115 - val_loss: 12.4538 - val_accuracy: 0.8750\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 85.4599 - accuracy: 0.3971 - val_loss: 71.3590 - val_accuracy: 0.1667\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 51.7247 - accuracy: 0.4211 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 28.2934 - accuracy: 0.3493 - val_loss: 2.4103 - val_accuracy: 0.4583\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 6.3864 - accuracy: 0.4593 - val_loss: 1.3915 - val_accuracy: 0.3333\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.4643 - accuracy: 0.4115 - val_loss: 0.7039 - val_accuracy: 0.0833\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7678 - accuracy: 0.3732 - val_loss: 0.6872 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6863 - accuracy: 0.3445 - val_loss: 0.6843 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6955 - accuracy: 0.3541 - val_loss: 0.6811 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6922 - accuracy: 0.3589 - val_loss: 0.6777 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6837 - accuracy: 0.3445 - val_loss: 0.6740 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6751 - accuracy: 0.3397 - val_loss: 0.6704 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6722 - accuracy: 0.2967 - val_loss: 0.6669 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6690 - accuracy: 0.3541 - val_loss: 0.6637 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6661 - accuracy: 0.3493 - val_loss: 0.6605 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6633 - accuracy: 0.3397 - val_loss: 0.6573 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6608 - accuracy: 0.3206 - val_loss: 0.6542 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6577 - accuracy: 0.3301 - val_loss: 0.6510 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6553 - accuracy: 0.3206 - val_loss: 0.6479 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6528 - accuracy: 0.3349 - val_loss: 0.6450 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6499 - accuracy: 0.3541 - val_loss: 0.6420 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6476 - accuracy: 0.3206 - val_loss: 0.6392 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6451 - accuracy: 0.3445 - val_loss: 0.6364 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14bb8540940>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# あとで顔検出など使いたくなる可能性あるので、最初からOpenCVでやる\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# ラベル付け(0春 1夏 2冬)\n",
    "# TODO: ? フォルダ名に数字入れておくとかのほうがいいかもしれない？\n",
    "def get_label(value):\n",
    "#     if value == \"Ariel\":\n",
    "#         return 192\n",
    "#     elif value == \"HAPPY\": \n",
    "#         return 201\n",
    "#     elif value == \"TOY\":\n",
    "#         return 211\n",
    "#     elif value == \"SAN\":\n",
    "#         return 212\n",
    "    if value == \"Ariel\":\n",
    "        return 0\n",
    "    elif value == \"HAPPY\": \n",
    "        return 1\n",
    "    elif value == \"TOY\":\n",
    "        return 2\n",
    "    elif value == \"SAN\":\n",
    "        return 3\n",
    "    \n",
    "# ラベル更新したら一緒に更新する\n",
    "def max_label():\n",
    "    return 4\n",
    "    \n",
    "\n",
    "# 教師データ\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "# Image直下のフォルダを網羅（フォルダ名からファイルにラベル付けする）\n",
    "train_path = \"../image/train\"\n",
    "for dir in os.listdir(train_path):\n",
    "    # Windows環境だから無いけど念の為\n",
    "    if dir == \".DS_Store\":\n",
    "        continue\n",
    "        \n",
    "    dir_path = train_path + \"/\" + dir\n",
    "    label = get_label(dir)\n",
    "\n",
    "    for file in os.listdir(dir_path):\n",
    "        # Windows環境だから無いけど念の為\n",
    "        # TODO: というか画像以外は無視するようにしたい\n",
    "        if dir != \".DS_Store\":\n",
    "            file_path = dir_path + \"/\" + file\n",
    "            \n",
    "            # 正解ラベルの追加\n",
    "            train_labels.append(label)\n",
    "            \n",
    "            # 画像を1080x1080の正方形にリサイズ（機種によって縦長横長が混在しているので正方形）\n",
    "            # 1要素が[R,G,B]3要素を含む配列の25x25の２次元配列として読み込む\n",
    "            # [R,G,B]はそれぞれが0-255の配列。\n",
    "            image = np.array(Image.open(file_path).resize(size=(1024, 1024)))\n",
    "            # 配列を変換し、[[Redの配列],[Greenの配列],[Blueの配列]] のような形にする。\n",
    "            image = image.transpose(2, 0, 1)\n",
    "            # さらにフラットな1次元配列に変換。最初の1/3はRed、次がGreenの、最後がBlueの要素がフラットに並ぶ。\n",
    "            image = image.reshape(image.shape[0] * image.shape[1] * image.shape[2], 1)\n",
    "            # 出来上がった配列をimage_listに追加。\n",
    "            train_images.append(image / 255.)\n",
    "            # ほぼ写経 https://zenn.dev/hiroe_orz17/articles/53af65f491122e\n",
    "            \n",
    "# kerasに渡すためにnumpy配列に変換        \n",
    "train_images = np.array(train_images)\n",
    "\n",
    "# ラベルの配列を1と0からなるラベル配列に変更\n",
    "# 0 -> [1,0], 1 -> [0,1] という感じ。\n",
    "Y = to_categorical(train_labels)\n",
    "\n",
    "# ラベル配列の中身を見たいときはコレ\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print(Y)\n",
    "\n",
    "# モデルの構築\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(3145728,1)),\n",
    "    keras.layers.Dense(200),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(200),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(max_label()),\n",
    "    keras.layers.Activation(\"softmax\")\n",
    "])\n",
    "print(model.summary())\n",
    "\n",
    "# オプティマイザにAdamを使用\n",
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "# モデルをコンパイル\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "# 学習を実行。10%はテストに使用。\n",
    "model.fit(train_images, Y, epochs=30, batch_size=100, validation_split=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c78215c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "20200206-134540_MobileL7_100000000_0.00_0.00_C249-SET-000-XXX_225.bmp\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 0 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n",
      "--------------------------------------------------------\n",
      "20200518-202340_MobileL4_100000000_0.00_0.00_C249-SET-000-XXX_205.bmp\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 0 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n",
      "--------------------------------------------------------\n",
      "20200519-095934_MobileL4_100000000_0.00_0.00_C249-SET-000-XXX_185.bmp\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 0 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n",
      "--------------------------------------------------------\n",
      "20200520-154352_MobileL2_100000000_0.00_0.00_C249-SET-000-XXX_220.bmp\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 0 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n",
      "--------------------------------------------------------\n",
      "20210413-131911_MobileL3_100000000_0.00_0.00_HAPPY-SET-000-XXX_2番目A_1番目B_.bmp\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 1 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n",
      "--------------------------------------------------------\n",
      "20210413-140430_MobileL4_100000000_0.00_0.00_HAPPY-SET-000-XXX_2番目A_1番目C_.bmp\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 1 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n",
      "--------------------------------------------------------\n",
      "20210823-130244_E0(L).jpg\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 1 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n",
      "--------------------------------------------------------\n",
      "20211019-163907_MobileL7_100000000_0.80_-0.23_SAN-UP-00-TATE.bmp\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 3 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n",
      "--------------------------------------------------------\n",
      "20211020-171825_MobileL6_100000000_0.80_-0.23_SAN-UP-00-TATE.bmp\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 3 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n",
      "--------------------------------------------------------\n",
      "20211021-165050_MobileL4_102000000_0.80_-0.23_SAN-UP-00-YOKO.bmp\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 3 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n",
      "--------------------------------------------------------\n",
      "20210702-184620_J0(L).jpg\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 2 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n",
      "--------------------------------------------------------\n",
      "20210706-132358_E0(L).jpg\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 2 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n",
      "--------------------------------------------------------\n",
      "20211019-110721_MobileL6_100000000_3.00_0.52_SET-000-XXX_.bmp\n",
      "[[0.26489434 0.24023947 0.26130664 0.23355949]]\n",
      "label: 2 result: [0.26489434 0.24023947 0.26130664 0.23355949]\n"
     ]
    }
   ],
   "source": [
    "# テスト用ディレクトリの画像でチェック。正解率を表示する。\n",
    "total = 0.\n",
    "ok_count = 0.\n",
    "\n",
    "test_path = \"../image/test\"\n",
    "for dir in os.listdir(test_path):\n",
    "    if dir == \".DS_Store\":\n",
    "        continue\n",
    "\n",
    "    dir_path = test_path + \"/\" + dir\n",
    "    label = get_label(dir)\n",
    "\n",
    "    for file in os.listdir(dir_path):\n",
    "        if file != \".DS_Store\":\n",
    "            print(\"--------------------------------------------------------\")\n",
    "            print(file)\n",
    "            file_path = dir_path + \"/\" + file\n",
    "            image = np.array(Image.open(file_path).resize(size=(1024, 1024)))\n",
    "            image = image.transpose(2, 0, 1)\n",
    "            image = image.reshape(image.shape[0] * image.shape[1] * image.shape[2], 1)\n",
    "#             image = image / 255.\n",
    "#             print(image.shape)\n",
    "            result = model.predict(np.array([image / 255.]))\n",
    "            print(result)\n",
    "            print(\"label:\", label, \"result:\", result[0])\n",
    "\n",
    "#             total += 1.\n",
    "\n",
    "#             if label == result[0]:\n",
    "#                 ok_count += 1.\n",
    "\n",
    "# print(\"seikai: \", ok_count / total * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c334d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
