{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb3b4517",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-e0a268b7e9b4>, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-e0a268b7e9b4>\"\u001b[1;36m, line \u001b[1;32m62\u001b[0m\n\u001b[1;33m    eye_path + file.replace(image_path,\"\")).replace(os.sep,\"/\")\u001b[0m\n\u001b[1;37m                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Activation, Conv2, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adagrad, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# データを正方形にリサイズするときの辺の長さ\n",
    "square_length = 1080\n",
    "\n",
    "# 画像を置いてるパス\n",
    "image_path = \"../image\"\n",
    "\n",
    "# ラベル付け(0春 1夏 2冬)\n",
    "# TODO: ? フォルダ名に数字入れておくとかのほうがいいかもしれない？\n",
    "# TODO: 3つ以上に増やす場合は、class_modeやlossをbinaryからcategricalに変える\n",
    "def get_label(value):\n",
    "    if value == \"Ariel\":\n",
    "        return 0\n",
    "    elif value == \"Other\":\n",
    "        return 1\n",
    "    \n",
    "# ラベル更新したら一緒に更新する\n",
    "def max_label():\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顔・瞳検出 https://note.nkmk.me/python-opencv-face-detection-haar-cascade/\n",
    "face_cascade_path = 'D:/python/OpenCV/data/haarcascades/haarcascade_frontalface_default.xml'\n",
    "eye_cascade_path = 'D:/python/OpenCV/data/haarcascades/haarcascade_eye.xml'\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(face_cascade_path)\n",
    "eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
    "\n",
    "left_eye_cascade_path = 'D:/python/OpenCV/data/haarcascades/haarcascade_lefteye_2splits.xml'\n",
    "right_eye_cascade_path = 'D:/python/OpenCV/data/haarcascades/haarcascade_righteye_2splits.xml'\n",
    "left_eye_cascade = cv2.CascadeClassifier(left_eye_cascade_path)\n",
    "right_eye_cascade = cv2.CascadeClassifier(right_eye_cascade_path)\n",
    "\n",
    "\n",
    "# 瞳だけトリミングした画像を保存する\n",
    "eye_path = image_path + \"/eye\"\n",
    "# if not(os.path.exists(eye_path)):\n",
    "# もうeyeフォルダあったら処理しない\n",
    "# なかったらeyeフォルダ作る\n",
    "# os.mkdir(eye_path)\n",
    "\n",
    "# 画像全部見る\n",
    "for file in glob.glob(image_path + \"/**/*\", recursive=True):\n",
    "    if os.path.splitext(file)[1] in [\".jpg\", \".png\", \".bmp\"]:\n",
    "        # cv2.imreadが日本語ファイル名に対応していないので、一旦Pillowで読み込んでから変換する\n",
    "        # https://qiita.com/derodero24/items/f22c22b22451609908ee\n",
    "        src = np.array(Image.open(file), dtype=np.uint8)\n",
    "        if src.ndim == 2:  # モノクロ\n",
    "            pass\n",
    "        elif src.shape[2] == 3:  # カラー\n",
    "            src = cv2.cvtColor(src, cv2.COLOR_RGB2BGR)\n",
    "        elif src.shape[2] == 4:  # 透過\n",
    "            src = cv2.cvtColor(src, cv2.COLOR_RGBA2BGRA)       \n",
    "        src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = face_cascade.detectMultiScale(src_gray)\n",
    "\n",
    "        # 保存先パス周りの整備(フォルダなかったら作る)\n",
    "        dst_path = (eye_path + file.replace(image_path,\"\")).replace(os.sep,\"/\")\n",
    "        os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "        split_dst_path = os.path.splitext(dst_path)\n",
    "        \n",
    "        # 顔→瞳を検出\n",
    "        for x, y, w, h in faces:\n",
    "            cv2.rectangle(src, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            face = src[y: y + h, x: x + w]\n",
    "            face_gray = src_gray[y: y + h, x: x + w]\n",
    "#             eyes = eye_cascade.detectMultiScale(face_gray)\n",
    "            eye_count = 0\n",
    "#             for (ex, ey, ew, eh) in eyes:\n",
    "#                 # 瞳1つずつトリミング\n",
    "#                 eye = src[y + ey: y + ey + eh, x + ex: x + ex + ew]\n",
    "                \n",
    "#                 # 保存\n",
    "#                 each_dst_path = split_dst_path[0] + \"_\" + str(eye_count) + split_dst_path[1]\n",
    "#                 cv2.imwrite(each_dst_path, eye)\n",
    "                \n",
    "#                 eye_count += 1\n",
    "            left_eyes = left_eye_cascade.detectMultiScale(face_gray)\n",
    "            for (ex, ey, ew, eh) in left_eyes:\n",
    "                # 瞳1つずつトリミング\n",
    "                eye = src[y + ey: y + ey + eh, x + ex: x + ex + ew]\n",
    "                \n",
    "                # 保存\n",
    "                each_dst_path = split_dst_path[0] + \"_\" + str(eye_count) + split_dst_path[1]\n",
    "                cv2.imwrite(each_dst_path, eye)\n",
    "                \n",
    "                eye_count += 1\n",
    "            right_eyes = right_eye_cascade.detectMultiScale(face_gray)\n",
    "            for (ex, ey, ew, eh) in right_eyes:\n",
    "                # 瞳1つずつトリミング\n",
    "                eye = src[y + ey: y + ey + eh, x + ex: x + ex + ew]\n",
    "                \n",
    "                # 保存\n",
    "                each_dst_path = split_dst_path[0] + \"_\" + str(eye_count) + split_dst_path[1]\n",
    "                cv2.imwrite(each_dst_path, eye)\n",
    "                \n",
    "                eye_count += 1\n",
    "#                 cv2.rectangle(face, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb061086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の読み込み\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    "#     validation_split=0.1\n",
    "    )\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    \"../image/train\",\n",
    "    target_size=(square_length, square_length),\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    subset='training',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "684c05ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 47s 47s/step - loss: 0.7145 - accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.6928 - accuracy: 0.4375\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.6898 - accuracy: 0.5312\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.6523 - accuracy: 0.7188\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.6314 - accuracy: 0.6562\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.6428 - accuracy: 0.5938\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.4951 - accuracy: 0.8750\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.5558 - accuracy: 0.7188\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.6401 - accuracy: 0.5833\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.5143 - accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.6014 - accuracy: 0.6250\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.5514 - accuracy: 0.6875\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.5825 - accuracy: 0.6562\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.4315 - accuracy: 0.7812\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.6085 - accuracy: 0.5938\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.6059 - accuracy: 0.5938\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.5603 - accuracy: 0.6250\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.4290 - accuracy: 0.7812\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.5475 - accuracy: 0.6250\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.4715 - accuracy: 0.6875\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.4940 - accuracy: 0.6562\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.5233 - accuracy: 0.7188\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.4442 - accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.4596 - accuracy: 0.9375\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.4519 - accuracy: 0.8125\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.5136 - accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.5091 - accuracy: 0.7188\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.4589 - accuracy: 0.8750\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.3998 - accuracy: 0.9583\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.3900 - accuracy: 0.9062\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1792)              17673816  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1793      \n",
      "=================================================================\n",
      "Total params: 17,675,609\n",
      "Trainable params: 1,793\n",
      "Non-trainable params: 17,673,816\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# モデルの構築\n",
    "model = keras.Sequential([\n",
    "#     keras.layers.Conv2D(32, (8,8), activation=\"relu\"),\n",
    "#     keras.layers.Conv2D(32, (8,8), activation=\"relu\"),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
    "#     keras.layers.Flatten(),\n",
    "#     keras.layers.Dropout(0.2),\n",
    "#     keras.layers.Dense(200, activation=\"relu\"),\n",
    "#     keras.layers.Dropout(0.4),\n",
    "#     keras.layers.Dense(200, activation=\"relu\"),\n",
    "#     keras.layers.Dropout(0.4),\n",
    "#     keras.layers.Dense(1),\n",
    "#     keras.layers.Activation(\"softmax\")\n",
    "    hub.KerasLayer(\n",
    "        \"https://tfhub.dev/tensorflow/efficientnet/b4/feature-vector/1\",\n",
    "        trainable=False,\n",
    "    ),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "# memo: shapeで警告出るのは、keras.layers.reshape((...)),imput_shape=(...))を使えば良さそう\n",
    "\n",
    "# # モデルをコンパイル\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "# 学習を実行\n",
    "model.fit(train_generator, steps_per_epoch=1, epochs=30)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de7267f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46749255]]\n",
      "[[0.7382952]]\n",
      "[[0.43541092]]\n",
      "[[0.6447168]]\n",
      "[[0.74514014]]\n",
      "[[0.7324718]]\n",
      "[[0.6442177]]\n",
      "[[0.5168108]]\n"
     ]
    }
   ],
   "source": [
    "# テスト用ディレクトリの画像でチェック。正解率を表示する。\n",
    "total = 0.\n",
    "ok_count = 0.\n",
    "\n",
    "test_path = \"../image/test\"\n",
    "for dir in os.listdir(test_path):\n",
    "    if dir == \".DS_Store\":\n",
    "        continue\n",
    "\n",
    "    dir_path = test_path + \"/\" + dir\n",
    "    label = get_label(dir)\n",
    "\n",
    "    for file in os.listdir(dir_path):\n",
    "        if file != \".DS_Store\":\n",
    "            file_path = dir_path + \"/\" + file\n",
    "            image = np.array(Image.open(file_path).resize(size=(square_length, square_length)))\n",
    "#             image = image.transpose(2, 0, 1)\n",
    "#             image = image.reshape(image.shape[0] * image.shape[1] * image.shape[2], 1)\n",
    "            result = model.predict(np.array([image / 255.]))\n",
    "            print(result)\n",
    "#             print(\"label:\", label, \"result:\", result[0])\n",
    "\n",
    "#             total += 1.\n",
    "\n",
    "#             if label == result[0]:\n",
    "#                 ok_count += 1.\n",
    "\n",
    "# print(\"seikai: \", ok_count / total * 100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
